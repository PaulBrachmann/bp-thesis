{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VoxelMorph Inferencing\n",
    "\n",
    "This example is based on [Learn2Reg](https://www.kaggle.com/adalca/learn2reg).\n",
    "\n",
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vxm_model_file = \"vxm/models/cvpr2018_vm2_l2.h5\" # MICCAI18: \"vxm/models/miccai2018_10_02_init1.h5\"\n",
    "\n",
    "scans_path = \"/mnt/h/ml/ventricles/scans/\"\n",
    "mni_path = \"/mnt/h/ml/\"\n",
    "\n",
    "registered_output = \"registered.csv\"\n",
    "baseline_output = \"unregistered.csv\"\n",
    "difference_output = \"diff.csv\"\n",
    "mni_output = \"mni.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy scipy sklearn nibabel matplotlib pprint tqdm\n",
    "\n",
    "# Imports\n",
    "import os, sys\n",
    "import csv\n",
    "\n",
    "# Third party imports\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import keras.layers\n",
    "import keras.models\n",
    "from scipy import ndimage as nd\n",
    "\n",
    "# Local imports\n",
    "sys.path.append(\"vxm/ext/pynd-lib/\")\n",
    "sys.path.append(\"vxm/ext/pytools-lib/\")\n",
    "sys.path.append(\"vxm/ext/neuron/\")\n",
    "sys.path.append(\"vxm/voxelmorph/\")\n",
    "sys.path.append(\"vxm/voxelmorph/voxelmorph/\")\n",
    "\n",
    "import voxelmorph as vxm\n",
    "import neuron\n",
    "import neuron.layers as nrn_layers\n",
    "\n",
    "# Limit GPU memory\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.7\n",
    "set_session(tf.Session(config=config))\n",
    "\n",
    "# Utilities\n",
    "def padwidth(width):\n",
    "    width = np.max((0, width)) / 2\n",
    "    return int(np.ceil(width)), int(np.floor(width))\n",
    "\n",
    "def cropwidth(width):\n",
    "    width = np.min((0, width))\n",
    "    width = np.abs(wid) / 2\n",
    "    return int(np.ceil(width)), int(np.floor(width))\n",
    "\n",
    "def padcrop(img, x=256, y=256, z=256):\n",
    "    \"\"\"\n",
    "    Pads or crops a rescaled scan to given target dimensions x,y,z\n",
    "    \"\"\"\n",
    "    new_img = np.zeros((x, y, z))\n",
    "    target_dim = np.array((x, y, z))\n",
    "    difs = target_dim - np.array(img.shape)\n",
    "    cropped_img = None\n",
    "    if np.any(difs < 0):\n",
    "        crop_x = cropwidth(difs[0])\n",
    "        crop_y = cropwidth(difs[1])\n",
    "        crop_z = cropwidth(difs[2])\n",
    "        cropped_img = img[crop_x[0]:(img.shape[0] - crop_x[1]), crop_y[0]:(img.shape[1] - crop_y[1]),\n",
    "                      crop_z[0]:(img.shape[2] - crop_z[1])]\n",
    "    else:\n",
    "        cropped_img = img\n",
    "    if np.any(difs > 0):\n",
    "        new_img[:, :, :] = np.pad(cropped_img, (padwidth(difs[0]), padwidth(difs[1]), padwidth(difs[2])),\n",
    "                                  mode=\"constant\")\n",
    "    else:\n",
    "        new_img[:, :, :] = cropped_img\n",
    "    return new_img\n",
    "\n",
    "def load_nii_unnormalized(path):\n",
    "    img = nib.load(path)\n",
    "    pixdim = img.header[\"pixdim\"]\n",
    "    img = img.get_data()\n",
    "    img = nd.interpolation.rotate(img, 90, (1, 2))\n",
    "    \n",
    "    pixdim = [pixdim[1], pixdim[3], pixdim[2]]\n",
    "    scale_factor = min([a / (b * c) for (a, b, c) in zip(vol_shape, img.shape, pixdim)])\n",
    "    img = nd.interpolation.zoom(\n",
    "        img,\n",
    "        (scale_factor * pixdim[0], scale_factor * pixdim[1], scale_factor * pixdim[2]),\n",
    "        mode = \"nearest\",\n",
    "        prefilter = False)\n",
    "    return padcrop(img, 160, 192, 224)\n",
    "\n",
    "def load_nii(path):\n",
    "    img = load_nii_unnormalized(path)\n",
    "    return img.astype(\"float\") / np.max(img)\n",
    "\n",
    "def dsc(y_true, y_pred):\n",
    "    top = 2 * np.sum(y_true * y_pred)\n",
    "    bottom = max(np.sum(y_true) + np.sum(y_pred), 1e-5)\n",
    "    return top / bottom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our data will be of shape 160 x 192 x 224\n",
    "vol_shape = [160, 192, 224]\n",
    "ndims = 3\n",
    "\n",
    "custom_objects = {\"SpatialTransformer\": nrn_layers.SpatialTransformer,\n",
    "                 \"VecInt\": nrn_layers.VecInt,\n",
    "                 \"Sample\": vxm.networks.Sample,\n",
    "                 \"Rescale\": vxm.networks.RescaleDouble,\n",
    "                 \"Resize\": vxm.networks.ResizeDouble,\n",
    "                 \"Negate\": vxm.networks.Negate,\n",
    "                 \"recon_loss\": vxm.losses.Miccai2018(0.02, 10).recon_loss, # values shouldn't matter\n",
    "                 \"kl_loss\": vxm.losses.Miccai2018(0.02, 10).kl_loss        # values shouldn't matter\n",
    "                 }\n",
    "\n",
    "vxm_model = keras.models.load_model(vxm_model_file, custom_objects=custom_objects)\n",
    "warp_model = vxm.networks.nn_trf(vol_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan_names = os.listdir(scans_path)\n",
    "scan_names.sort()\n",
    "\n",
    "with open(registered_output, \"w\") as csvfile:\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    csvwriter.writerow([\"F\\M\"] + [i / 2 for i in range(0, len(scan_names) - 1, 2)])\n",
    "\n",
    "    for i in range(0, len(scan_names) - 1, 2):\n",
    "        fixed_val = load_nii(scans_path + scan_names[i + 1])\n",
    "        fixed_seg = load_nii(scans_path + scan_names[i])\n",
    "\n",
    "        print(scan_names[i + 1])\n",
    "        row = [i / 2]\n",
    "        for j in range(0, len(scan_names) - 1, 2):\n",
    "            moving_val = load_nii(scans_path + scan_names[j + 1])\n",
    "            moving_seg = load_nii(scans_path + scan_names[j])\n",
    "\n",
    "            val_input = [moving_val[np.newaxis, ..., np.newaxis], fixed_val[np.newaxis, ..., np.newaxis]]\n",
    "            val_pred = vxm_model.predict(val_input)\n",
    "            moved_pred = val_pred[0].squeeze()\n",
    "            pred_warp = val_pred[1]\n",
    "\n",
    "            warped_seg = warp_model.predict([moving_seg[np.newaxis,...,np.newaxis], pred_warp])\n",
    "            dice = dsc(fixed_seg, warped_seg.squeeze())\n",
    "            row.append(dice)\n",
    "        csvwriter.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan_names = os.listdir(scans_path)\n",
    "scan_names.sort()\n",
    "\n",
    "with open(baseline_output, \"w\") as csvfile:\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    csvwriter.writerow([\"F\\M\"] + [i / 2 for i in range(0, len(scan_names) - 1, 2)])\n",
    "\n",
    "    for i in range(0, len(scan_names) - 1, 2):\n",
    "        fixed_seg = load_nii(scans_path + scan_names[i])\n",
    "\n",
    "        print(scan_names[i + 1])\n",
    "        row = [i / 2]\n",
    "        for j in range(0, len(scan_names) - 1, 2):\n",
    "            moving_seg = load_nii(scans_path + scan_names[j])\n",
    "\n",
    "            dice = dsc(fixed_seg, moving_seg)\n",
    "            row.append(dice)\n",
    "        csvwriter.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(baseline_output, \"r\") as unreg, open(registered_output, \"r\") as reg, open(difference_output, \"w\") as diff:\n",
    "    reader_u = csv.reader(unreg)\n",
    "    reader_r = csv.reader(reg)\n",
    "    writer = csv.writer(diff)\n",
    "\n",
    "    writer.writerow(next(reader_u))\n",
    "    next(reader_r)\n",
    "    for row_u in reader_u:\n",
    "        row_r = next(reader_r)\n",
    "        row = [float(r) - float(u) for (u, r) in zip(row_u, row_r)]\n",
    "        row[0] = row_u[0]\n",
    "        writer.writerow(row)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan_names = os.listdir(scans_path)\n",
    "scan_names.sort()\n",
    "\n",
    "moving_val = load_nii(os.path.join(mni_path, \"mni_icbm152_t1_tal_nlin_sym_09a.nii\")) * \\\n",
    "    load_nii(os.path.join(mni_path, \"mni_icbm152_t1_tal_nlin_sym_09a_mask.nii\"))\n",
    "\n",
    "moving_seg = load_nii_unnormalized(os.path.join(mni_path, \"mni_icbm152_CerebrA_tal_nlin_sym_09c.nii\"))\n",
    "moving_seg = np.logical_or(moving_seg == 41, moving_seg == 92)\n",
    "\n",
    "with open(mni_output, \"w\") as csvfile:\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    csvwriter.writerow([\"Fixed Image\", \"Accuracy [DSC]\"])\n",
    "\n",
    "    for j in range(0, len(scan_names) - 1, 2):\n",
    "        fixed_val = load_nii(scan_path + scan_names[j + 1])\n",
    "        fixed_seg = load_nii(scan_path + scan_names[j])\n",
    "\n",
    "        val_input = [moving_val[np.newaxis, ..., np.newaxis], fixed_val[np.newaxis, ..., np.newaxis]]\n",
    "        val_pred = vxm_model.predict(val_input)\n",
    "        moved_pred = val_pred[0].squeeze()\n",
    "        pred_warp = val_pred[1]\n",
    "\n",
    "        warped_seg = warp_model.predict([moving_seg[np.newaxis,...,np.newaxis], pred_warp])\n",
    "        dice = dsc(fixed_seg, warped_seg.squeeze())\n",
    "        csvwriter.writerow([scan_names[j + 1], dice])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fixed_val = load_nii(\"/mnt/h/ml/ventricles/scans/ventricle_1_t1.nii.gz\")\n",
    "fixed_seg = load_nii(\"/mnt/h/ml/ventricles/scans/ventricle_1_seg.nii.gz\")\n",
    "\n",
    "moving_val = load_nii(os.path.join(mni_path, \"mni_icbm152_t1_tal_nlin_sym_09a.nii\")) * \\\n",
    "    load_nii(os.path.join(mni_path, \"mni_icbm152_t1_tal_nlin_sym_09a_mask.nii\"))\n",
    "moving_seg = load_nii_unnormalized(os.path.join(mni_path, \"mni_icbm152_CerebrA_tal_nlin_sym_09c.nii\"))\n",
    "moving_seg = np.logical_or(moving_seg == 41, moving_seg == 92)\n",
    "\n",
    "# Predict\n",
    "val_input = [moving_val[np.newaxis, ..., np.newaxis], fixed_val[np.newaxis, ..., np.newaxis]]\n",
    "val_pred = vxm_model.predict(val_input)\n",
    "moved_pred = val_pred[0].squeeze()\n",
    "pred_warp = val_pred[1]\n",
    "warped_seg = warp_model.predict([moving_seg[np.newaxis,...,np.newaxis], pred_warp])\n",
    "\n",
    "# Save output\n",
    "# nib.save(nib.Nifti1Image((fixed_val[0,...,0] * 256).astype(int), None), \"fixed_val.nii.gz\")\n",
    "# nib.save(nib.Nifti1Image((fixed_seg[0,...,0] * 256).astype(int), None), \"fixed_seg.nii.gz\")\n",
    "# nib.save(nib.Nifti1Image((warped_seg[0,...,0] * 256).astype(int), None), \"warped_seg.nii.gz\")\n",
    "\n",
    "# Extract slices & plot\n",
    "mid_slices_fixed = [np.take(fixed_val, vol_shape[d]//2, axis=d) for d in range(ndims)]\n",
    "mid_slices_fixed[1] = np.rot90(mid_slices_fixed[1], 1)\n",
    "mid_slices_fixed[2] = np.rot90(mid_slices_fixed[2], -1)\n",
    "\n",
    "mid_slices_moving = [np.take(moving_val, vol_shape[d]//2, axis=d) for d in range(ndims)]\n",
    "mid_slices_moving[1] = np.rot90(mid_slices_moving[1], 1)\n",
    "mid_slices_moving[2] = np.rot90(mid_slices_moving[2], -1)\n",
    "\n",
    "mid_slices_pred = [np.take(moved_pred, vol_shape[d]//2, axis=d) for d in range(ndims)]\n",
    "mid_slices_pred[1] = np.rot90(mid_slices_pred[1], 1)\n",
    "mid_slices_pred[2] = np.rot90(mid_slices_pred[2], -1)\n",
    "neuron.plot.slices(mid_slices_fixed + mid_slices_pred + mid_slices_moving, cmaps=[\"gray\"], do_colorbars=True, grid=[3,3])\n",
    "\n",
    "# Visualize DVF\n",
    "flow = pred_warp[0, :, :, :, :]\n",
    "flow_sd = np.std(flow)\n",
    "v_args = dict(cmap = 'RdBu', vmin = -flow_sd, vmax = +flow_sd)\n",
    "fig, m_axs = plt.subplots(3, 3, figsize = (20, 10))\n",
    "for i, (ax1, ax2, ax3) in enumerate(m_axs):\n",
    "    ax1.imshow(np.mean(flow[:, :, :, i], 0), **v_args)\n",
    "    ax1.set_title('xyz'[i]+' flow')\n",
    "    ax2.imshow(np.mean(flow[:, :, :, i], 1), **v_args)\n",
    "    ax3.imshow(np.mean(flow[:, :, :, i], 2), **v_args)\n",
    "    \n",
    "def meshgridnd_like(in_img,\n",
    "                    rng_func=range):\n",
    "    new_shape = list(in_img.shape)\n",
    "    all_range = [rng_func(i_len) for i_len in new_shape]\n",
    "    return tuple([x_arr.swapaxes(0, 1) for x_arr in np.meshgrid(*all_range)])\n",
    "\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "DS_FACTOR = 16\n",
    "c_xx, c_yy, c_zz = [x.flatten()\n",
    "                    for x in \n",
    "                    meshgridnd_like(flow[::DS_FACTOR, ::DS_FACTOR, ::DS_FACTOR, 0])]\n",
    "\n",
    "get_flow = lambda i: flow[::DS_FACTOR, ::DS_FACTOR, ::DS_FACTOR, i].flatten()\n",
    "\n",
    "fig = plt.figure(figsize = (10, 10))\n",
    "ax = fig.gca(projection=\"3d\")\n",
    "\n",
    "ax.quiver(c_xx,\n",
    "          c_yy,\n",
    "          c_zz,\n",
    "          get_flow(0),\n",
    "          get_flow(1), \n",
    "          get_flow(2), \n",
    "          length=0.5,\n",
    "          normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact\n",
    "\n",
    "def plot(x):\n",
    "    fig, axs = neuron.plot.slices([\n",
    "        np.rot90(np.take(moving_val, x, axis=1), 1),\n",
    "        np.rot90(np.take(moved_pred, x, axis=1), 1),\n",
    "        np.rot90(np.take(fixed_val, x, axis=1), 1),\n",
    "        np.rot90(np.take(moving_seg, x, axis=1), 1),\n",
    "        np.rot90(np.take(warped_seg.squeeze(), x, axis=1), 1),\n",
    "        np.rot90(np.take(fixed_seg, x, axis=1), 1)\n",
    "    ], cmaps=[\"gray\"], do_colorbars=True, grid=[2,3])\n",
    "    # fig.savefig(\"f0_m1_s{}_3up.png\".format(x),bbox_inches='tight', dpi=300)\n",
    "\n",
    "interact(plot, x = 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
